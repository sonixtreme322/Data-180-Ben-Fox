warning = FALSE,
error = FALSE,
fig.align = "center",
cache = FALSE
# Custom options for knitting
knitr::opts_chunk$set(
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
error = FALSE,
fig.align = "center",
cache = FALSE
)
#library(tidyverse)
library(NLP)
library(tm)
news<-read.csv("news.csv",header=T)
posWords <- scan("positive-words.txt", character(0), sep = "\n")  # 2006 items
negWords <- scan("negative-words.txt", character(0), sep = "\n")  # 4783 items
head(posWords,15)
head(negWords,15)
#Scan the head of news to see what variables there are and how they're labelled
head(news)
#Get the largest and smallest year in that data set
most_recent <- max(news$year)
most_old <- min(news$year)
#Subtract oldest from youngest and get the full range of years.
year_range <- most_recent - most_old
#Return year_range, which is 18 years
year_range
#set headline_text as equal to charVector
charVector <- c(news$headline_text)
#Return the first 6 entries
head(charVector)
#Creates vector source object wordVector
wordVector <- VectorSource(charVector)
wordVector
charVector
wordVector
charVector
wordVector
?Corpus
?Corpus()
Corpus(wordVector)
wordVector
#Creates corpus object wordCorpus
wordCorpus <- Corpus(wordVector)
wordCorpus
?tm_map
# Custom options for knitting
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
error = FALSE,
fig.align = "center",
cache = FALSE
)
#library(tidyverse)
library(NLP)
library(tm)
news<-read.csv("news.csv",header=T)
posWords <- scan("positive-words.txt", character(0), sep = "\n")  # 2006 items
negWords <- scan("negative-words.txt", character(0), sep = "\n")  # 4783 items
head(posWords,15)
head(negWords,15)
#Scan the head of news to see what variables there are and how they're labelled
head(news)
#Get the largest and smallest year in that data set
most_recent <- max(news$year)
most_old <- min(news$year)
#Subtract oldest from youngest and get the full range of years.
year_range <- most_recent - most_old
#Return year_range, which is 18 years
year_range
#set headline_text as equal to charVector
charVector <- c(news$headline_text)
#Return the first 6 entries
head(charVector)
#Creates vector source object wordVector
wordVector <- VectorSource(charVector)
#Creates corpus object wordCorpus
wordCorpus <- Corpus(wordVector)
#Make all text lowercase
wordCorpus <- tm_map(wordCorpus, tolower(wordCorpus))
wordCorpus
head(wordCorpus)
#Remove all punctuation from the text
wordCorpus <- tm_map(wordCorpus, removePunctuation)
wordCorpus
#Remove all numbers from the corpus
wordCorpus <- tm_map(wordCorpus, removeNumbers)
wordCorpus
#Remove all stopwords
wordCorpus <- tm_map(wordCorpus, removeWords, stopwords("en"))
wordCorpus
#Creating a term document matrix called tdm using the described function
tdm <- TermDocumentMatrix(wordVector)
tdm
#Creating a term document matrix called tdm using the described function
tdm <- TermDocumentMatrix(charVector)
#Printing the newly created object
tdm
#Creating a term document matrix called tdm using the described function
tdm <- TermDocumentMatrix(wordVector)
#Printing the newly created object
tdm
#Printing the newly created object
tdm
#It's a matrix that returns the frequency of terms within a given corpus.
?TermDocumentMatrix
#Creating a term document matrix called tdm using the described function
tdm <- TermDocumentMatrix(charVector)
#Printing the newly created object
tdm
# Custom options for knitting
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
error = FALSE,
fig.align = "center",
cache = FALSE
)
#library(tidyverse)
library(NLP)
library(tm)
news<-read.csv("news.csv",header=T)
posWords <- scan("positive-words.txt", character(0), sep = "\n")  # 2006 items
negWords <- scan("negative-words.txt", character(0), sep = "\n")  # 4783 items
head(posWords,15)
head(negWords,15)
#Scan the head of news to see what variables there are and how they're labelled
head(news)
#Get the largest and smallest year in that data set
most_recent <- max(news$year)
most_old <- min(news$year)
#Subtract oldest from youngest and get the full range of years.
year_range <- most_recent - most_old
#Return year_range, which is 18 years
year_range
#set headline_text as equal to charVector
charVector <- c(news$headline_text)
#Return the first 6 entries
head(charVector)
#Creates vector source object wordVector
wordVector <- VectorSource(charVector)
#Creates corpus object wordCorpus
wordCorpus <- Corpus(wordVector)
#Make all text lowercase
wordCorpus <- tm_map(wordCorpus, tolower(wordCorpus))
#Remove all punctuation from the corpus
wordCorpus <- tm_map(wordCorpus, removePunctuation)
#Remove all numbers from the corpus
wordCorpus <- tm_map(wordCorpus, removeNumbers)
#Remove all stopwords
wordCorpus <- tm_map(wordCorpus, removeWords, stopwords("en"))
#Creating a term document matrix called tdm using the described function
tdm <- TermDocumentMatrix(charVector)
#Printing the newly created object
tdm
#Convert tdm into matrix m
m <- matrix(tdm)
m
#Convert tdm into matrix m
?matrix
#Convert tdm into matrix m
m <- as.matrix(tdm)
#Converting frequency of
m
#Convert tdm into matrix m
m <- matrix(tdm)
#Converting frequency of
m
# Custom options for knitting
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
error = FALSE,
fig.align = "center",
cache = FALSE
)
#library(tidyverse)
library(NLP)
library(tm)
news<-read.csv("news.csv",header=T)
posWords <- scan("positive-words.txt", character(0), sep = "\n")  # 2006 items
negWords <- scan("negative-words.txt", character(0), sep = "\n")  # 4783 items
head(posWords,15)
head(negWords,15)
#Scan the head of news to see what variables there are and how they're labelled
head(news)
#Get the largest and smallest year in that data set
most_recent <- max(news$year)
most_old <- min(news$year)
#Subtract oldest from youngest and get the full range of years.
year_range <- most_recent - most_old
#Return year_range, which is 18 years
year_range
#set headline_text as equal to charVector
charVector <- c(news$headline_text)
#Return the first 6 entries
head(charVector)
#Creates vector source object wordVector
wordVector <- VectorSource(charVector)
# Custom options for knitting
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
error = FALSE,
fig.align = "center",
cache = FALSE
)
#library(tidyverse)
library(NLP)
library(tm)
news<-read.csv("news.csv",header=T)
posWords <- scan("positive-words.txt", character(0), sep = "\n")  # 2006 items
negWords <- scan("negative-words.txt", character(0), sep = "\n")  # 4783 items
head(posWords,15)
head(negWords,15)
#Scan the head of news to see what variables there are and how they're labelled
head(news)
#Get the largest and smallest year in that data set
most_recent <- max(news$year)
most_old <- min(news$year)
#Subtract oldest from youngest and get the full range of years.
year_range <- most_recent - most_old
#Return year_range, which is 18 years
year_range
#set headline_text as equal to charVector
charVector <- c(news$headline_text)
#Return the first 6 entries
head(charVector)
#Creates vector source object wordVector
wordVector <- VectorSource(charVector)
class(wordVector); typeof(wordVector); length(wordVector)
#set headline_text as equal to charVector
charList <- c(new$headline_text)
#set headline_text as equal to charVector
charList <- c(news$headline_text)
#set headline_text as equal to charVector
charList <- c(news$headline_text)
for (i in charList) {
charVector(i) <- i
}
charVector
#set headline_text as equal to charVector
charList <- c(news$headline_text)
charVector
charVector(i) <- i
# Custom options for knitting
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
error = FALSE,
fig.align = "center",
cache = FALSE
)
#library(tidyverse)
library(NLP)
library(tm)
news<-read.csv("news.csv",header=T)
posWords <- scan("positive-words.txt", character(0), sep = "\n")  # 2006 items
negWords <- scan("negative-words.txt", character(0), sep = "\n")  # 4783 items
head(posWords,15)
head(negWords,15)
#Scan the head of news to see what variables there are and how they're labelled
head(news)
#Get the largest and smallest year in that data set
most_recent <- max(news$year)
most_old <- min(news$year)
#Subtract oldest from youngest and get the full range of years.
year_range <- most_recent - most_old
#Return year_range, which is 18 years
year_range
#set headline_text as equal to charVector
charList <- c(news$headline_text)
charVector
#set headline_text as equal to charVector
charList <- c(news$headline_text)
for (i in charList) {
charVector(i) <- i
}
print i
for (i in charList) {
print i
for (x in charList) {
print x
print(x)
for (x in charList) {
print(x)
}
remove(charVector)
for (x in charList) {
charVector(x) <- x
}
# Custom options for knitting
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
error = FALSE,
fig.align = "center",
cache = FALSE
)
#library(tidyverse)
library(NLP)
library(tm)
news<-read.csv("news.csv",header=T)
posWords <- scan("positive-words.txt", character(0), sep = "\n")  # 2006 items
negWords <- scan("negative-words.txt", character(0), sep = "\n")  # 4783 items
head(posWords,15)
#Scan the head of news to see what variables there are and how they're labelled
head(news)
#Get the largest and smallest year in that data set
most_recent <- max(news$year)
most_old <- min(news$year)
#Subtract oldest from youngest and get the full range of years.
year_range <- most_recent - most_old
#Return year_range, which is 18 years
year_range
#set headline_text as equal to charVector
charList <- c(news$headline_text)
for (x in charList) {
if x in charVector {
for (x in charList) {
if (x == 1) {
charVector <- c(charList[x])
} else {
charVector <- charVector + charList[x]
}
}
for (x in charList) {
charVector
if (x == 1) {
charVector <- c(charList[x])
} else {
charVector <- charVector + charList[x]
}
}
for (x in charList) {
charVector <- 1
if (x == 1) {
charVector <- c(charList[x])
} else {
charVector <- charVector + charList[x]
}
}
for (x in charList) {
charVector <- 1
if (charVector == 1) {
charVector <- c(charList[x])
} else {
charVector <- charVector + charList[x]
}
}
#Return the first 6 entries
head(charVector)
#Return the first 6 entries
charVector
#Creates vector source object wordVector
wordVector <- VectorSource(charVector)
class(wordVector); typeof(wordVector); length(wordVector)
charList
#Make it not a list anymore
charVector <- unlist(charList)
#Return the first 6 entries
charVector
#Creates vector source object wordVector
wordVector <- VectorSource(charVector)
class(wordVector); typeof(wordVector); length(wordVector)
#set headline_text as equal to charVector
charList <- c(news$headline_text)
#Make it not a list anymore
charVector <- unlist(charList)
#Return the first 6 entries
charVector
#Creates vector source object wordVector
wordVector <- VectorSource(charVector)
print(unlist(charList))
#Return the first 6 entries
charVector(1:6)
#Make it not a list anymore
charVector <- unlist(charList)
#Return the first 6 entries
charVector(1:6)
#Return the first 6 entries
charVector[c(1:6)]
class(charVector)
class(wordVector); typeof(wordVector); length(wordVector)
typeof(charVector)
length(charVector)
#Creates vector source object wordVector
wordVector <- VectorSource(charVector)
class(wordVector); typeof(wordVector); length(wordVector)
#Creates corpus object wordCorpus
wordCorpus <- Corpus(wordVector)
#Make all text lowercase
wordCorpus <- tm_map(wordCorpus, tolower(wordCorpus))
#Remove all punctuation from the corpus
wordCorpus <- tm_map(wordCorpus, removePunctuation)
#Remove all numbers from the corpus
wordCorpus <- tm_map(wordCorpus, removeNumbers)
#Remove all stopwords
wordCorpus <- tm_map(wordCorpus, removeWords, stopwords("en"))
#Creating a term document matrix called tdm using the described function
tdm <- TermDocumentMatrix(charVector)
#Printing the newly created object
tdm
#Convert tdm into matrix m
m <- matrix(tdm)
#Getting word frequency
wordCounts <-
```
#Getting word frequency
wordCounts <- findFreqTerms(m)
#Getting word frequency
wordCounts <- findFreqTerms(tdm)
print(wordCounts(1:10))
print[c(wordCounts(1:10))]
wordCounts
#Getting word frequency
wordCounts <- findFreqTerms(m)
#Convert tdm into matrix m
m <- matrix(tdm)
#Getting word frequency
wordCounts <- findFreqTerms(m)
#Getting word frequency
wordCounts <- findFreqTerms(tdm)
wordCounts
# Custom options for knitting
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
error = FALSE,
fig.align = "center",
cache = FALSE
)
#library(tidyverse)
library(NLP)
library(tm)
news<-read.csv("news.csv",header=T)
posWords <- scan("positive-words.txt", character(0), sep = "\n")  # 2006 items
negWords <- scan("negative-words.txt", character(0), sep = "\n")  # 4783 items
head(posWords,15)
head(negWords,15)
#set headline_text as equal to charVector
charList <- c(news$headline_text)
#Make it not a list anymore
charVector <- unlist(charList)
#Return the first 6 entries
charVector[1:6]
#Creates vector source object wordVector
wordVector <- VectorSource(charVector)
class(wordVector); typeof(wordVector); length(wordVector)
#Creates corpus object wordCorpus
wordCorpus <- Corpus(wordVector)
#Make all text lowercase
wordCorpus <- tm_map(wordCorpus, content_transformer(tolower))
#Remove all punctuation from the corpus
wordCorpus <- tm_map(wordCorpus, removePunctuation)
#Remove all numbers from the corpus
wordCorpus <- tm_map(wordCorpus, removeNumbers)
#Remove all stopwords
wordCorpus <- tm_map(wordCorpus, removeWords, stopwords("en"))
#Creating a term document matrix called tdm using the described function
tdm <- TermDocumentMatrix(wordCorpus)
#Printing the newly created object
tdm
#Convert tdm into matrix m
m <- as.matrix(tdm)
#Getting word frequency
wordCounts <- rowSums(m)
#Sorts the words from most to least commonly used
wordCounts <- sort(wordCounts, decreasing = TRUE)
#Grabs the first 10 entries in that list
wordCounts[1:10]
#Create new list where only words that occur at least 50 times
bleh <- wordCounts[wordCounts >= 50]
#Graph their frequency
barplot(bleh, horiz = TRUE, cex.names = 0.75, las = 2)
#Find all the positive words and their frequencies in common_news_words
positive_word_frequency <- wordCounts[names(wordCounts) %in% posWords]
#Get the ones that appeared at least 20 times
positive_word_frequency <- positive_word_frequency[positive_word_frequency >= 20]
#Graph the frequency of positive words
barplot(positive_word_frequency, las = 2)
#Find all the negative words and their frequencies in common_news_words
negative_word_frequency <- wordCounts[names(wordCounts) %in% negWords]
#Get the ones that appeared at least 20 times
negative_word_frequency <- negative_word_frequency[negative_word_frequency >= 20]
#Graph the frequency of positive words
barplot(negative_word_frequency, las = 2)
news <- news %>% group_by(year,month) %>% mutate(count=n(), yearmonth = paste(year, month,sep = '/')) %>% arrange(year,month,day)
#Get ggplot library
library(ggplot2)
#Get yearmonth as a y axis
yearmonth <- news$yearmonth
tdm <- TermDocumentMatrix(yearmonth)
m <- as.matrix(tdm)
news_frequency <- rowSums(m)
#Do bar graph, looks close enough, distinct spike around the middle ish.
ggplot(news, aes(x = yearmonth)) + geom_bar()
#Do bar graph, looks close enough, distinct spike around the middle ish.
ggplot(news, aes(x = yearmonth)) + geom_bar()
rlang::last_trace()
#Do bar graph, looks close enough, distinct spike around the middle ish.
ggplot(data = news, aes(x = yearmonth)) + geom_bar()
#Do bar graph, looks close enough, distinct spike around the middle ish.
ggplot(data = news, aes(x = news$yearmonth)) + geom_bar()
#Do bar graph, looks close enough, distinct spike around the middle ish.
ggplot(data = news, aes(x = yearmonth)) + geom_bar()
#install.packages("quanteda")
install.packages("corpus")
